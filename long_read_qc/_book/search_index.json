[["01-Long_read_QC.html", "Long read Quality Control Chapter 1 Overview", " Long read Quality Control Matthew Gemmell &amp; Helen Hipperson 2021-03-16 Chapter 1 Overview This practical session aims to introduce you to Long read Quality Control. The topics covered are: Acquiring the workshop data Example of PacBio quality control Example of ONT quality control Practice data Further resources "],["02-Intro.html", "Chapter 2 Data 2.1 The data", " Chapter 2 Data 2.1 The data The data for today is in the \"QC_workshop\" directory that you copied into your home directory (~) in the Illumina QC day. Check you have the directory. ls ~ If you do not have this directory the command to copy it to your home directory is below. cp -r /pub39/tea/matthew/NEOF/QC_workshop/ ~ "],["03-PB.html", "Chapter 3 PacBio 3.1 File formats 3.2 Continuous Long Reads 3.3 Circular Consensus Sequences", " Chapter 3 PacBio In this section we will quality check PacBio sequencing raw data (BAM files), perform a filter to retain only the longest reads and output the data in fastq format. 3.1 File formats Sequence data from PacBio are output as subreads in unaligned BAM format. (Further explanation of the BAM format is in section 4.1.3). The figure below shows a schematic of a circular DNA molecule of a PacBio library with the colours representing: Black, I = Insert DNA, i.e. the double-stranded DNA of your sample Red, B = Barcodes, optional single (Left or Right) or double (Left &amp; Right) for multiplexing samples Green, A = Adapter, SMRTbell adapters with a double-stranded stem and single-stranded hairpin loop. Sequencing follows the direction of the arrows and continues around until either the end of the sequencing run or if the DNA polymerase fails. A ZMW read consists of the data collected from a single ZMW, with the HQ (high quality) region recorded when just a single molecule of DNA is present in the ZMW. This schematic shows the structure of a ZMW read in linear format. Insert DNA subreads are interspersed with the barcode and adapter sequence of the SMRTbell library. For more information see: https://pacbiofileformats.readthedocs.io/en/10.0/Primer.html subreads.bam file This contains the sequence for each read (or pass) of the insert DNA (grey). scraps.bam file This contains the adapter (green) and barcode (red) sequences, as well as any low quality (black) regions. These BAM files will usually have an accompanying PacBio BAM index file (subreads.bam.pbi and scraps.bam.pbi). PacBio data can be treated in two ways depending on the goal of the experiment. With Continuous Long Reads (CLR) the aim is to produce sequence reads as long as possible, such as for genome assembly, sequencing through long repeat regions or finding other large structural variants. With Circular Consensus Sequences (CCS) the aim is to sequence shorter molecules (up to 10-15kb), such as amplicons, and to generate accurate consensus sequences. CLR runs usually generate one subread and seqeunces have a higher error rate than CCS runs that generate higher-accuracy sequences from a consensus of many subreads. For this tutorial we will carry out quality checking and control on both CLR and CCS BAM files. SequelTools https://github.com/ISUgenomics/SequelTools We will use the SequelTools program to both assess and filter our PacBio CLR and CCS data. smrttools https://www.pacb.com/wp-content/uploads/SMRT_Tools_Reference_Guide_v90.pdf We will also use smrttools from PacBio to generate any missing index files and CCS reads from subreads BAM files, plus convert BAM to fasta/q format. 3.2 Continuous Long Reads Before carrying out any specific commands we will first move into the relevant directory. cd ~/QC_workshop/PB_QC/data/CLR Use ls to list the contents of this directory. You will see that there are BAM subreads and scraps files for three samples, plus their BAM index files. We will use the SequelTools program to both assess and filter our PacBio CLR data. First we need to make a file of filenames (fofn) for the subreads files. You can do this with the following commands: find $(pwd) -name &quot;*subreads.bam&quot; &gt; CLR_subreads.txt This command line will find all of the files in our current working directory whose names end in subreads.bam and prints these names into a new text file. The SequelTools program has three different tools, specified with the -t argument. The options for -t are: Q for quality control S for subsampling the data F for filtering the data We will first use Q to assess our data. Other options used are: -u to specify the file containing the list of subread .bam files -o to specify the name of an output folder for the plots -p to specify which plots to produce. b for a few basic plots, i includes a few more detailed plots and a generates all available plots. SequelTools.sh -t Q -p a -u CLR_subreads.txt -o CLR_QC When this has finished running the CLR_QC folder will contain a 'summaryTable.txt' file with values on the number and lengths of sequence reads for all three samples, plus a series of plots saved as pdf files. We can use firefox to view the pdf plots. firefox CLR_QC/totalBasesBarplot.pdf This shows the total amount of sequence data for each of the three samples, both for all of the subreads present and 'longestSubs' (the longest subread within each CLR). We can see that Sample2 has the largest amount of data, and for all three samples most of the data is contained within the longest subreads. This is expected with CLR data - lomg fragments of DNA are extracted for sequenicng and we often achieve just a single pass of this insert during the PacBio sequenicng run. There are also plots for the N50 and L50 of each sample: firefox CLR_QC/n50s.pdf CLR_QC/l50s.pdf N50 = the median sequence length (in bp) of the data; 50% of the sequence data generated is in subreads equal or greater than this length. L50 = the minimum number of subreads whose length makes up the N50 value. We can see that the N50 is larger for Sample3 compared to Sample1 and Sample2. find $(pwd) -name &quot;*scraps.bam&quot; &gt; CLR_scraps.txt 3.3 Circular Consensus Sequences Before carrying out any specific commands we will first move into the relevant directory. cd ~/QC_workshop/PB_QC/data/CCS "],["04-ONT.html", "Chapter 4 ONT 4.1 File formats 4.2 Basecalling 4.3 QC of fastq file", " Chapter 4 ONT In this section we are going to carry out a quick QC of ONT data using the tool suite NanoPack and the tool Porechop. For this we will use the fastq files. 4.1 File formats Although we will only be using fastq files for this tutorial it is important to know the other file formats you may encounter when working with ONT data. 4.1.1 Fast5 The raw data from ONT machines come as Fast5 (.fast5) files. This contains the signal data from the pore which can be processed into more useful files. Fast5 files can contain: Raw signal data Run metadata fastq-basecalls Other additional analyses The Fast5 file format is an implementation of the HDF5 file format specifically for ONT sequencing data. For more information on Fast5 and a tool to interface with these types of file please see: https://github.com/nanoporetech/ont_fast5_api 4.1.2 Summary file The MinION and GridION output a single sequencing summary file in addition to the Fast5 files. This file contains metdata which descirbes each sequenced read. We will not use Fast5 or summary files for this tutorial as they are not needed most of the time. It is likely these files will not be intially provided to you by a sequencing service as they are very large. However, if you do require them you can always ask but be careful with how long the sequencing centre will retain your data. 4.1.3 BAM file BAM files (.bam) are the binary version of SAM files (.sam). This means: BAM files are not human readable whilst SAM files are. SAM files are larger than BAM. Generally programs that can work on SAM files can also work on BAM files. Due to the size difference it is preferable to store data in BAM format over SAM. Even though a BAM file is smaller than their matching SAM file, BAM files are still very large and can be &gt;100GB. SAM stands for \"Sequence Alignment/Map\" (the B in BAM is Binary). SAM files are tab delimited and contain alignment information. It can be useful to contain unaligned reads from sequencing machines (e.g. PacBio and ONT) in BAM files as they can contain more metadata in the header and per-record auxiliary tags compared to fastq files. If you are working with SAM/BAM files the following link will prove useful: https://www.htslib.org/ For more information on the SAM and BAM format please see: https://samtools.github.io/hts-specs/SAMv1.pdf 4.1.4 fastq file The fastq file format is very consistent and so there is no real difference between fastq files for Illumina, PacBio, and ONT data. All fastq files will contain a number of lines divisible by 4. This is because each entry/sequence will take up four lines consisting of the following information: Header for fastq entry known as the fastq header. This always begins with a @ This is where you might see the most difference between different data. Different machines and different public databases will use different formats for fastq headers. Sequence content Quality header Always begins with a '+'. Sometimes also contains the same information as fastq header. Quality Each base in the 2nd line will have a corresponding quality value in this line. Note this uses Phred encoding, of which there are different formats. Most, if not all, new files will use Phred+33 but be careful if you are using older data as it may use a different one. See the Encoding section in the following link for more info: https://en.wikipedia.org/wiki/FASTQ_format. NOTE: '@' can be used as a quality value. An example of the information of one sequence/entry is: @Sequence 1 CTGTTAAATACCGACTTGCGTCAGGTGCGTGAACAACTGGGCCGCTTT + =&lt;&lt;&lt;=&gt;@@@ACDCBCDAC@BAA@BA@BBCBBDA@BB@&gt;CD@A@B?B@@ 4.2 Basecalling In short, basecalling is the converting of ONT signals to bases and quality. This step converts the Fast5 files to BAM and/or fastq files. There are many tools to carry out basecalling with ONT data. ONT sequencing machines carry this out with in built programs. However, if you are interested in the tools used for this the primary ones are Guppy and Albacore. Unfortunately it is quite hard to find information about these tools unless you own an ONT machine. Basecalling with Guppy tutorial: https://denbi-nanopore-training-course.readthedocs.io/en/latest/basecalling/basecalling.html Basecalling with Albacore tutorial: https://denbi-nanopore-training-course.readthedocs.io/en/stable/basecalling/basecalling.html 4.3 QC of fastq file For this tutorial we will carry out quality control and checking on fastq files. Some QC steps can be carried out on summary files and/or BAM files. However we will be using fastq files for a variety of reasons: Fastq files are the smallest and so these processes will run quicker and the files will take up less storage. Ideal for a tutorial. Fastq files are the easiest to work with. You will most likely use fastq files in the future for ONT data. If you get your data sequenced by a genomic centre they will most likely give you your data in demultiplexxed (one fastq file per sample) fastq files. ONT machines generally come with in built basecalling and so will most likely provide fastq files as well as the other formats now. Before carrying out any specific commands we will first move into the relevant directory. cd ~/QC_workshop/ONT_QC/ We need to initialise the environment to use the programs we need. This needs to be done in each terminal you want to run the below commands in. Each terminal will only remember what you have told that terminal. . usenanopack-1.1.0 Look in the directory called data and you will notice there are a few directories. You can see the contents of all these directories with the below command. ls data/* Each directory has one fastq file. ONT data likes to be organised with data for one sample being in one directory. To start with we will only use the fastq file within the directory called \"Acinetobacter\". As you may have figured out, this contains ONT sequencing data of an Acinetobacter genome. Specifically the data is a subset of the SRA (Sequence Read Archive) Run: SRR7119550. 4.3.1 NanoStat The first step is to acquire stats for the sequences in our fastq file. We will use NanoStat (https://github.com/wdecoster/nanostat). NanoStat is one of the many tools contained in the NanoPack suite (https://github.com/wdecoster/nanopack). We will also use the tools NanoPlot and NanoFilt downstream. We want to have a tidy set of directories at the end of this analysis. It would be an untidy mess if we had all the output files in the current directory. We will therefore be making directories and subdirectories to send our output. mkdir nanostats Finally we will now run NanoStat. The options used are: -n : File name/path for the output. -t : Number of threads the script can use. --fastq : Input data is in fastq format. Other options that can be used are --fasta, --summary, and --bam. NanoStat -n nanostats/Acinetobacter_nanostats.tsv \\ -t 4 --fastq ./data/Acinetobacter/Acinetobacter_genome_ONT.fastq Now we can look at the output text file. In this case we will use the convenient less command. less nanostats/Acinetobacter_nanostats.tsv 4.3.1.1 NanoStat output format The file contains four sections with informative headers. These are: General summary A list of general summary metrics. Number, percentage and megabases of reads above quality cutoffs Based on the mean quality value of a read. The \"&gt;Q5\" line shows the number and % of reads with a mean quality above Q5. It also shows the total amount of megabases these reads contain. Top 5 highest mean basecall quality scores and their read lengths Shows the top 5 reads with the highest mean quality scores. Top 5 longest reads and their mean basecall quality score Shows the top 5 longest reads. 4.3.2 Porechop Porechop is a tool to find and remove adapters from ONT data (https://github.com/rrwick/Porechop). Adapters are artificial sequences essential for sequencing but of no biological value and so you will typically want them removed. Porechop is no longer supported but it still works and there is no alternative for adapter removal. Depending on which basecaller was used on your data, adapter removal may have already been carried out. However, it is always best to run porechop if you are not sure. Porechop has a list of known adapters it will look for and remove. These contain: Ligation kit adapters Rapid kit adapters PCR kit adapters Barcodes Native barcoding Rapid barcoding Porechop will look for these adapters at the start and end of each read. Then it will look for adapters within the sequence (known as middle adapters to Porechop). If it finds a middle adapter it will conclude that the read is chimeric (a recombinant read containing sequence from 2 or more reads) and split the read. Depending on the number of middle adpaters the chimeric read may split into 2 or more reads. With all that explanation we will now run Porechop. Thankfully the command is relatively straight forward with the options: -t: Number of threads to be used. -i: Input path of a fasta file, fastq file, or a directory. If a directory is specified it will be recursively searched for fastq files. -o: Output path. This will either be a fastq or fasta file name. #Create output directory mkdir porechop #Run porechop command porechop -t 4 -i ./data/Acinetobacter/Acinetobacter_genome_ONT.fastq \\ -o porechop/Acinetobacter.porechop.fastq Porechop will take a while to run. Whilst it is running, look at the screen output to get an idea of what it is doing. When finished, look at the bottom of the printed results. Questions: How many reads had adapters trimmed from their start? How many bases were removed by adapters being trimmed from the end of reads? How many reads were split based on middle adpaters? For more uses of Porechop please see the below links: https://github.com/rrwick/Porechop#quick-usage-examples https://github.com/rrwick/Porechop#full-usage 4.3.3 NanoPlot NanoPlot can be thought of as the FastQC for ONT data. It produces a lot of useful visualisations to investigate the quality of ONT sequencing data. It can be used for fastq, fasta, bam, and sequencing summary files. The link for its github page is: https://github.com/wdecoster/NanoPlot ONT data has much lower quality scores than Illumina with Q10 being good. If you have enough coverage and length the low quality can be corrected by downstream processes not covered in this tutorial. Prior to running NanoPlot we will make a directory for the NanoPlot output. As NanoPlot creates a lot of files, we'll make a subdirectory for the NanoPlot output for the porechopped data. mkdir nanoplot mkdir nanoplot/porechop Now to run NanoPlot. The options we will use are: -t: Number of threads to be used. --fastq: Specifies the input path which is a fastq file. -o: Directory where the output will be created. -p: Prefix of output files. It is useful to have \"_\" at the end of the prefix. --plots: Specifies what type of bivariate plot is to be created (more on this later). I find hex to be the best. NanoPlot -t 4 \\ --fastq porechop/Acinetobacter.porechop.fastq \\ -o nanoplot/porechop -p Acinetobacter_ \\ --plots hex You may get the below warning. This is fine and can be ignored. /pub37/matt/programs_chos_8/anaconda3/lib/python3.7/_collections_abc.py:702: MatplotlibDeprecationWarning: The global colormaps dictionary is no longer considered public API. return len(self._mapping) /pub37/matt/programs_chos_8/anaconda3/lib/python3.7/_collections_abc.py:720: MatplotlibDeprecationWarning: The global colormaps dictionary is no longer considered public API. yield from self._mapping List the files in the output directory. ls nanoplot/porechop/ There are quite a few files. These should all start with \"Acinetobacter_\" thanks to the -p option. To quickly check all the results we can open the report html file with firefox. firefox nanoplot/porechop/Acinetobacter_NanoPlot-report.html 4.3.3.1 NanoPlot output format The first section contains NanoStat output. Quickly look over this and see how it compares to the NanoStat output of the pre-porechopped reads. Tip: To open a new terminal, right click VNC background -&gt; Applications -&gt; Shells -&gt; Bash. After the Summary Statistics section there is a Plots section. This contains the plots: Histogram of read lengths Histogram of \"Number of reads\" (y) against Read length (x). Histogram of read lengths after log transformations Histogram of \"Number of reads\" (y) against log transformed Read length (x). Weighted Histogram of read lengths Histogram of \"Number of bases\" (y) against \"Read length\" (x). Weighted Histogram of read lengths after log transformation Histogram of \"Number of bases\" (y) against log transformed \"Read length\" (x). Dynamic histogram of Read length An interactive Histogram of \"Number of reads\" (y) against \"Read length\" (x) produced by plotly (https://plotly.com/). You can zoom into areas by clicking and dragging. Make boxes to zoom into a specific area. Click and drag left or right only to zoom into a specific part of the x axis. Click and drag up or down only to zoom into a specific part of the y axis. Click the home icon on the top right to reset the axes. Yield by length Plot showing the \"Cumulative yield for minimal length\" (y) by Read length (x). The cumulative yield is measured in Gigabases (billion bases). This plot is useful to know how many bases you would retain if you filtered reads based on read length. Read lengths vs Average read quality plot using hexagonal bins This is the most informative plot. It is the bivariate plot we indicated we wanted as hexagonal with the option --plots hex. Each hex is a bin with a darker colour representing more reads. At the top of the plot is a histogram of Number of reads against read lengths. At the right of the plot is a sideways histogram of number of reads against average read quality. Questions to be answered with the html file: How long is the longest read? What is the highest mean basecall quality score of a read? How many reads have a mean basecall quality score &gt;Q10? Approximately where is the highest density of reads in terms of read lengths and average read quality. Roughly, do the longer reads have relatively high, medium, or low mean qualities? Using different input files will give you different plots. For more details please see the Plots Generated section on: https://github.com/wdecoster/NanoPlot. 4.3.4 NanoFilt NanoFilt can be used to remove/filter reads by quality and/or read length (https://github.com/wdecoster/nanofilt). This is very useful as you will most likely want long and good quality reads for downstream processes, such as genome assemblies. It is always important to know what your data is and if your planned filtering and trimming is appropriate. For example, you may be working with amplicon data where the read lengths will vary between 500bp and 750bp. In that case it is useful to set a min length of 500 and a maxlength of 750. This data is from a genome so wanting long and high quality reads is appropriate. Overall quality looks good. The main exception is the low amount of sequencing/coverage. The low coverage is because it is a subset of the whole data for workshop purposes (the full dataset would take too long to run through). There are some shorter length and lower quality reads which we will remove. First we will create an output directory. mkdir nanofilt We will filter out sequences that are shorter than 500bp (-l 500bp) and filter out sequences with a average read quality less than Q10 (-q 10). We have chosen these values as they are a good default for genomic data. Q10 appeared to be a good choice from NanoPlot as the majority of reads had a quality of &gt;Q10. cat porechop/Acinetobacter.porechop.fastq | \\ NanoFilt -l 500 -q 10 &gt; \\ nanofilt/Acinetobacter.nanofiltq10minlen500.porechop.fastq Are the chosen options appropriate? Lets find out. 4.3.5 Final check After trimming or filtering reads (quality control) it is always important to carry out a quality check. We will therefore run NanoPlot again. Note: We are using a long informative output directory name. This is important as we may need to rerun NanoFilt a few more times with different options until we are happy. #Make an output directory before running NanoPlot mkdir nanoplot/nanofiltq10minlen500_porechop #Run NanoPlot on the fastq file with the filtered and porechopped data NanoPlot -t 4 \\ --fastq nanofilt/Acinetobacter.nanofiltq10minlen500.porechop.fastq \\ -o nanoplot/nanofiltq10minlen500_porechop/ -p Acinetobacter_ \\ --plots hex Now inspect the report firefox nanoplot/nanofiltq10minlen500_porechop/Acinetobacter_NanoPlot-report.html Ultimately when quality checking we need to take into account how much data we are left with. We need to make sure we have a good amount of bases and reads for our application. However, we also want to make sure we arent left with a lot of poor quality data. Depending on our application the quality of the reads may be less important, or the other way around. The is the same with the amount of reads and bases. What is needed will be clearer when you know what type of data you have. These considerations will be covered in our future workshops of the specific data types A quick example is data for a genome assembly. For this type of analysis we will want our number of bases to reach a certain coverage. Well want a decent quality but a high coverage can help overcome lower quality (more on this in a future workshop). Generally for ONT assemblies you will want 20X - 100X coverage with a higher coverage producing a better assembly (100x coverage= 100bp sequencing data per 1bp of the genome size). Higher coverages may be worse as it can be too much information for an assembly algorithm to cope with. In addition to the amount of bases, the length of reads is also important. One read that is 10kbp long is most likely better than 10 reads that are each 1kbp long for a genome assembly. This is because less reads will need to be assembled. Keeping all this in mind, let's say this sequencing is for a genome with a size of 0.5 Mbp (0.5 million base pairs). We want at least 20X coverage (i.e 10,000,000.0 total bases). Do we have this for the data that was porechopped and nanofiltered? If not, try running NanoFilt with a different choices for --q until you do. What is an option that works to get the desired coverage? Is the overall quality decent (Mean &amp; Median read quality &gt; 10)? What is the N50 of your QC'd reads? How many extra reads and bases did you retain compared to the Q10 filtering? Tips: Make sure your new output paths have unique names. Use NanoPlot results to compare the Q10 filtering to your own. The NanoStat part is especially helpful. "],["05-Practice.html", "Chapter 5 Practice 5.1 ONT data", " Chapter 5 Practice This section contains information on more data that you can carry out QC (Quality control and checking) as self guided practice. 5.1 ONT data The extra data consists of 2 subsetted runs from Bio Project: PRJNA477342 (https://www.ncbi.nlm.nih.gov/bioproject/?term=prjna477342). The data sets are: Flavobacterium Genomic data for a Flavobacterium isolate. Original data from: SRA run SRR7449788. Pseudonocardia Genomic data for a Pseudonocardia isolate. Original data from: SRA run SRR7447112. Run through all the ONT QC steps for these two datasets. Use all the same parameters and options, making sure to change input and output file paths and prefixes where appropriate. Tips: If you are editing commands you previously ran it is best to change the outputs first so you don't accidentally overwrite previous results. You can run the command firefox nanoplot/*/*NanoPlot*html. This will open all the NanoPlot report htmls in one firefox window. There will be a separate tab for each report. Questions: Which of the three datasets (Acinetobacter, Flavobacterium, and Pseudocardia) has the highest initial (pre porechopping) mean read quality (this may be more than one)? Which of the three datasets has the highest initial mean read length? Which of the three datasets has the longest read in the initial data? How long is the read and what is it mean basecall quality score? Answer questions 1-3 for the porechopped data. Are the results of NanoStats significantly changed for any of the samples? Look at the NanoPlot results for the porechopped and NanoFiltered data using -l 500 and -q 10. How many bases and reads are removed from the samples due to NanoFilt? Are the parameters too stringent for some of the samples (losing too much data)? Try out some different parameters until you are happy with the results. Ultimately, knowing what is good and poor data takes experience and practice. The -l 500 and -q10 is a good default for ONT genomic data and may be good for other uses. As with all defaults you may need to change these for your particular data. Hopefully that has been good practice and you are ready to QC your own data. "],["06-Furter_resources.html", "Chapter 6 Further resources 6.1 Long read sequencing resources 6.2 PacBio resources 6.3 ONT resources 6.4 Tools 6.5 Misc", " Chapter 6 Further resources 6.1 Long read sequencing resources Comparison of the two up-to-date sequencing technologies for genome assembly: HiFi reads of Pacific Biosciences Sequel II system and ultralong reads of Oxford Nanopore https://academic.oup.com/gigascience/article/9/12/giaa123/6034784 Opportunities and challenges in long-read sequencing data analysis https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-1935-5 6.2 PacBio resources Pacbio glossary of terms https://www.pacb.com/wp-content/uploads/2015/09/Pacific-Biosciences-Glossary-of-Terms.pdf Pacbio Brochure https://www.pacb.com/wp-content/uploads/SMRT-Sequencing-Brochure-Delivering-highly-accurate-long-reads-to-drive-discovery-in-life-science.pdf PacBio Sequencing 101: Understanding Accuracy in DNA Sequencing https://www.pacb.com/blog/understanding-accuracy-in-dna-sequencing/ Sequel systems https://www.pacb.com/products-and-services/sequel-system/ 6.3 ONT resources Products comparison https://nanoporetech.com/products/comparison Nanopore accuracy https://nanoporetech.com/accuracy Adaptive Sampling https://nanoporetech.com/about-us/news/towards-real-time-targeting-enrichment-or-other-sampling-nanopore-sequencing-devices Blog on history of Nanopore sequencing https://www.whatisbiotechnology.org/index.php/science/summary/nanopore/nanopore-sequencing-makes-it-possible-to-decode-the 6.4 Tools LONG-READ-TOOLS https://long-read-tools.org/ 6.5 Misc What's N50 https://www.molecularecologist.com/2017/03/29/whats-n50/ "]]
